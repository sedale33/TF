{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Family of Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Gaussian Naive Bayes Classifer\n",
    "class GaussNB():\n",
    "    def fit(self, X, y, epsilon = 1e-2):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]\n",
    "            mu_k = X_k.mean(axis=0)\n",
    "            self.likelihoods[k] = {\"mean\":mu_k, \"cov\":X_k.var(axis=0) + epsilon}\n",
    "            self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        P_hat = np.zeros((N,len(self.K)))\n",
    "        \n",
    "        for k, l in self.likelihoods.items():\n",
    "            P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "            \n",
    "        return P_hat.argmax(axis = 1)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Gaussian Bayes Classifer\n",
    "class GaussBayes():\n",
    "    def fit(self, X, y, epsilon = 1e-2):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:] #All X's in class y==k\n",
    "            N_k, D = X_k.shape #Dimensions of X's in class k\n",
    "            mu_k = X_k.mean(axis=0) #Mean of row values\n",
    "            self.likelihoods[k] = {\"mean\": mu_k, \"cov\":(1/(N_k - 1))*np.matmul(X_k.T,X_k-mu_k) + epsilon*np.identity(D)}\n",
    "            self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        N, D = X.shape #Shape of variable table\n",
    "        P_hat = np.zeros((N,len(self.K))) #Zero array N(rows) x K(columns)\n",
    "        \n",
    "        for k, l in self.likelihoods.items():\n",
    "            P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "            \n",
    "        return P_hat.argmax(axis = 1) #column wise\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Multinomial Naive Bayes Classifer\n",
    "class MultinoNB():  \n",
    "    def fit(self, X, y, epsilon = 1e-3):\n",
    "        self.sum = []\n",
    "        self.priors = []\n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]  \n",
    "            N = X.shape[0]\n",
    "            self.sum.append(X_k.sum(axis=0) + epsilon)\n",
    "            self.priors.append(np.log(len(X_k) / N))\n",
    "        \n",
    "        self.log_prob = np.log(np.array(self.sum) / np.array(self.sum).sum(axis=1)[np.newaxis].T)  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        P_hat = [(self.log_prob * x).sum(axis=1) + self.priors for x in X]\n",
    "        return np.argmax(P_hat, axis=1)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Bernoulli Naive Bayes Classifer\n",
    "class BernoNB():\n",
    "    def fit(self, X, y, epsilon= 1e-2):\n",
    "        self.sum = []\n",
    "        self.priors = []\n",
    "        self.class_obs = []\n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]  \n",
    "            N = X.shape[0]\n",
    "            self.sum.append(X_k.sum(axis=0) + epsilon)\n",
    "            self.priors.append(np.log(len(X_k) / N))\n",
    "            self.class_obs.append(len(X_k) + 2 * epsilon)\n",
    "            \n",
    "        self.probs = np.array(self.sum) / np.array(self.class_obs)[np.newaxis].T\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        P_hat = [(np.log(self.probs) * x + np.log(1 - self.probs) * np.abs(x - 1)).sum(axis=1) + self.priors for x in X]\n",
    "        return np.argmax(P_hat, axis=1)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
